{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ravibalija/anaconda3/envs/modelexpenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Praveen Kumar V – Da\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "\n",
    "######### Content Processing Block ###############################\n",
    "\n",
    "## Loading PDF file from local file directory\n",
    "## read the content and store it in data object \n",
    "local_path = \"./alphabet/Praveen_13Yrs_Datascience_AI.pdf\"\n",
    "\n",
    "if local_path:\n",
    "    loader = UnstructuredPDFLoader(file_path=local_path)\n",
    "    data = loader.load()\n",
    "else:\n",
    "    print(\"Upload a PDF file for processing.\")\n",
    "\n",
    "print(data[0].page_content[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([Document(metadata={'source': './alphabet/Praveen_13Yrs_Datascience_AI.pdf'}, page_content='Praveen Kumar V – Data science, AI – 13 plus Yrs – IIIT Hyderabad\\n\\nPhone: 9663045588 email: praveenv8ai@gmail.com LinkedIn: https://www.linkedin.com/in/praveen-kumar-62a95212/\\n\\nExecutive Summary\\n\\nHighly skilled data science professional, leader, adept at translating business problems into actionable data-driven solutions. Proficient to apply respective skills to deliver innovative scalable and impactful results that align with organizational goals.\\n\\nExploring potential Analytics Leadership roles that leverage experience gained across – diverse areas in\\n\\nBusiness Transformation • Pharma Mfg, eCommerce, D2C\\n\\n• People Excellence & Team management\\n\\nInnovation, Strategic Thinking\\n\\nBusiness Leadership Communication • Stakeholder Success Enablement\\n\\nAnalytics Technical and Leadership Competencies\\n\\nHands on Execution • Proficient Analytical, Problem-solving skills • Product Management, vision implementation • Data Engineering and pipeline development • Data Visulisation and communication\\n\\nAnalytics, ML, NLP, AI Solutioning • AI (LLM, RAG, Embeddings) skills • Statistical Analysis, EDA-Insights • Predictive, Cluster Modeling • Deep Learning Frameworks\\n\\nCross functional Collaboration • Business Acumen, Design Thinking • Mentorship and Coaching • Continuous Improvement mindset • Python programming, Cloud skills\\n\\nAcademia ▪ Full Time PG (MSIT) 8.21/10 CGPA, IIIT-Hyderabad, 2007-2010. ▪ Full Time B.Sc. (Mathematics, Physics, Chemistry), Osmania\\n\\nUniversity- Hyderabad, 2002-2005.\\n\\nHands on Technologies Data science / AI Python libraries: Pandas, Scikit-learn, Seaborn, Numpy, Spacy, Gensim, statsmodels, PyPDF, BeautifulSoup, LangChain, Llamaindex. Others: Linux Shell Scripting, OOPs-Java.\\n\\nCertifications ▪ Product Management certification, ISB Hyd, Feb to May 2023. ▪ Recently graduated in a 2-month in-class “Leadership” training\\n\\nprogram offered by Samsung partnered with Knolskape.\\n\\nMachine learning / AI models techniques: Linear Regression, Logistic Regression, Decision Tree Models, Bagging & Boosting Ensemble models, Naïve Bayes, KNN, Neural Networks, SVM, K Means, Encoding, Data Cleaning, Feature Engineering, Regularization, Normalization, LLMs, Vector DBs.\\n\\nProjects ( reverse chronological order): Highlighting few of interesting projects, not listed many other ad-hoc short projects.\\n\\n1. Samsung R&D Institute, Bangalore, Data science Manager (Since June 2022) Technologies used: BigQuery SQL, Superset, open source LLMs, RAG, Milvus, LangChian, LlamaIndex, Steamlit, Docker\\n\\nAnalyzed global D2C data, highlighted customer pain points towards successful product purchase in our ecommerce portal - Increased D2C sales significantly at several countries by fixing customer drop areas in customer experience journey - Owned, built a state-of-the art AI solution in NL to SQL space, that increased the TAT of delivering critical analytics insights - Designed, Developed, Delivered several critical high visible short analytics projects / Insights - Lead a team of 15, that includes Data Engineers, Data Analysts, Data Scientists\\n\\n2. Gramener, Hyderabad, Lead Data Scientist (July 2019 to June 2022)\\n\\nClients: DrReddys Laboratories (Pharma), Dubai Tourism (Govt)\\n\\nTechnologies used: Python’s scikit learn, Exploratory Analysis, ML Regression & classification – ensemble models, Flask, Camelot, Statistical Models, NLP – Process FDA data, OCR models, CNN, DataIku, R Studio\\n\\nOptimised the drug mfg stages to achieve consistent yield using predictive models, that saved $20M worth of production loss - Built predictive models on IVIVR (InVitro, InVivo) drug release data that reduces the experiments to quickly arrive at conclusion - Built NLP models on FDA Inspection data, that helps org to know FDA Auditors focus areas in prior to their visit to the Mfg Plant - Scraped and analysed a health care website to utilize the data to build strategies for sales & marketing - Analysed Tourism data and shared insights to Tourism department of Dubai govt to support country’s tourism revenue growth - An Individual contributor, also a Lead that managed 5 data analysts\\n\\n3. DataJango, Hyderabad, Partner Datascientist / Trainer /Consultant (Jan 2019 to July 2019)\\n\\nTechnologies used: Datasciece related Python libraries, Text modeling (NLP) techniques, Keras, Tensorflow, Pytorch, C/RNN models. - Partnered with this organisation to develop Datascience course content, and offer respective hands on trainings - Being an analytics consultant helped several startups to build Datascience capability & competency in their organisation - Built RNN models (PoC) to automate Customer Service operations of a reputed Indian Power company\\n\\n4. Mphasis, Hyderabad, BigData Analyst (Sep 2017 to Aug 2018)\\n\\nClient: JP Morgan & Co.\\n\\nTechnologies used: Spark, Scala, Java, REST API, Org’s own software frameworks. - Developed Spark scripts to perform data transformations in a large scale data ingestion pipeline - Built a Spark job trigger & monitoring script to achieve speed and efficiency in successful data migrations - Analysed CCF data to prepare features for respective ML models\\n\\n5. Bridgei2i Analytics Solutions, Bangalore , Senior Analytics Consultant (May 2015 to Sep 2017)\\n\\nClient: Internal, Ab-inbev, P&G, Bajaj Finance.\\n\\nTechnologies used: Hive, Apache Spark, REST API, R Studio, Python Pandas, Numpy, statsmodels, sklearn, NLTK - Contributed in building org’s products in Marketing space. - Developed a ‘Lead Engine’ using Intent Marketing concepts to identify potential Leads in B2B domain - Generated insights for Finance, and retail sectors using cluster analysis, and exploratory analysis techniques - Built SKU recommendation engine ( a predictive model) for a popular retail organisation - Offered ad-hoc analysis support to several analytics projects simultaneously\\n\\n6. IBM India, Bangalore, Unix Operations Professional (July 2011 to Feb 2015)\\n\\nClient: Internal\\n\\nTechnologies used: AIX, Solaris, VIOS (power VM), HMC, Linux-RedHat setup & migrations, IBM/HP/ECM storage migrations, HACMP/PowerHA Cluster builds, Apache Hadoop, IBM Infosphere. - Majorly accomplished server migrations from legacy systems to modern virtual IBM infrastructure - Automated Unix/Linux OS upgrades, and patches installations - Performed Computing resources management and Storage management following business demands - Configured & managed Power HA clusters, Hadoop Clusters. - Developed MapReduce programs to benchmark data transformations\\n\\n7. JNTU/ IIIT, Hyderabad, Assistant Mentor for MSIT program (for 4 Months in Year 2010)\\n\\nTechnologies worked with: eCommerce technologies - Enterprise Java Beans, PHP, Java Script, Android Development, Data Structures, Java, Pearl, Python Programming Languages, Shell Script, MySQL, Postgres DDL, DML, MS Office.\\n\\nDesigned, and developed the content for several IT courses to be offered for MSIT Program - Mentored and offered eCommerce projects for MSIT program students at JNTU, IIIT H learning centers - Conducted weekly assessment, evaluated and provided the feedback, assigned credits.')],\n",
       " langchain_core.documents.base.Document)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data,type(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting content into dense vector embeddings \n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma \n",
    "\n",
    "#Split and chunk the data\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=7500, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(data)\n",
    "\n",
    "\n",
    "# Add the chunks to vector database, which takes the model for creating the embeddings.\n",
    "# vector_db = Chroma.from_documents(\n",
    "#                                     documents=chunks, \n",
    "#                                     embedding=OllamaEmbeddings(model=\"nomic-embed-text\", show_progress=True),\n",
    "#                                     persist_directory=\"resume_db\"\n",
    "#                                 )\n",
    "\n",
    "vector_db = Chroma(persist_directory='resume_db', embedding_function=OllamaEmbeddings(model=\"nomic-embed-text\", show_progress=True))\n",
    "#https://github.com/hwchase17/chroma-langchain/blob/master/persistent-qa.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Retrieval + Generation of Response ##############################\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "# local_llm = \"llama3.1\" #latest 4.9GB\n",
    "local_llm = \"llama3.2\" #1.3GB\n",
    "llm = ChatOllama(model=local_llm)\n",
    "\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables = [\"question\"],\n",
    "    template=\"\"\"You are an AI Language model assistant. Your task is to generate five different versions of the given user question to retrieve relavant documents from a vector databaase. By generating multiple perspectives on the user question, your goal is to help the user overcome some of the limitations of the distance-based similarity search. Provide these alternative questions separated by newlines. \n",
    "    Original question: {question} \"\"\"\n",
    ")\n",
    "\n",
    "retriever = MultiQueryRetriever.from_llm(vector_db.as_retriever(),llm, prompt=QUERY_PROMPT)\n",
    "\n",
    "# RAG Prompt\n",
    "template = \"\"\"Answer the question based ONLY on the following context: \n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"Give me the list of companies Paraveen worked for\"\n",
    "chain = (\n",
    "    {\"context\":retriever, \"question\":RunnablePassthrough()}\n",
    "    | prompt \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 35.53it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 20.67it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 46.31it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 42.30it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 44.11it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 24.24it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 38.70it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given context, here is a list of companies that Praveen Kumar V has worked for:\n",
      "\n",
      "1. Samsung R&D Institute, Bangalore\n",
      "2. Gramener, Hyderabad\n",
      "3. DataJango, Hyderabad\n",
      "4. Mphasis, Hyderabad\n",
      "5. Bridgei2i Analytics Solutions, Bangalore\n",
      "6. IBM India, Bangalore\n",
      "\n",
      "Note that Praveen also mentions IIIT Hyderabad as his alma mater and the institute where he completed his PG (MSIT) and B.Sc. programs, but it's not explicitly mentioned as a company he worked for.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(user_question)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 75.31it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 60.76it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 31.22it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 64.87it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 44.40it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 69.41it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the document, Praveen possesses the following technical skills:\n",
      "\n",
      "1. Data Science / AI:\n",
      "\t* Python libraries: Pandas, Scikit-learn, Seaborn, Numpy, Spacy, Gensim, statsmodels, PyPDF, BeautifulSoup, LangChain\n",
      "2. Machine Learning / AI models techniques:\n",
      "\t* Linear Regression\n",
      "\t* Logistic Regression\n",
      "\t* Decision Tree Models\n",
      "\t* Bagging & Boosting Ensemble models\n",
      "\t* Naïve Bayes\n",
      "\t* KNN\n",
      "\t* Neural Networks\n",
      "\t* SVM\n",
      "\t* K Means\n",
      "3. Data Engineering and pipeline development:\n",
      "\t* BigQuery SQL\n",
      "\t* Superset\n",
      "\t* open source LLMs (RAG, Milvus)\n",
      "4. Data Visualization and communication:\n",
      "\t* Data Visualization using tools like LangChain, LlamaIndex, Steamlit\n",
      "5. Cloud skills:\n",
      "\t* Python programming with cloud capabilities\n",
      "6. Programming languages:\n",
      "\t* Java\n",
      "\t* Pearl\n",
      "7. Scripting languages:\n",
      "\t* Linux Shell Scripting\n",
      "8. Other technologies:\n",
      "\t* Docker\n",
      "\t* Flask\n",
      "\t* Camelot\n",
      "\t* Statistical Models (R Studio)\n",
      "\t* NLP - Process FDA data, OCR models, CNN\n"
     ]
    }
   ],
   "source": [
    "user_question = \"What are technical skills does Praveen Possess ?\"\n",
    "chain = (\n",
    "    {\"context\":retriever, \"question\":RunnablePassthrough()}\n",
    "    | prompt \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "response = chain.invoke(user_question)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By llama3.2:1b outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 74.10it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 34.54it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 68.70it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 67.47it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 45.64it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 46.13it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 69.99it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 41.87it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 70.07it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 71.32it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 44.07it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context provided, here is a list of companies that Praveen Kumar V worked for:\n",
      "\n",
      "1. Samsung R&D Institute, Bangalore\n",
      "2. Gramener, Hyderabad\n",
      "3. DataJango, Hyderabad\n",
      "4. Mphasis, Hyderabad\n",
      "5. Bridgei2i Analytics Solutions, Bangalore\n",
      "6. IBM India, Bangalore\n",
      "7. Osmania University - Hyderabad (as a student)\n",
      "8. IIIT-Hyderabad (as a student and later as an Assistant Mentor for MSIT program)\n"
     ]
    }
   ],
   "source": [
    "user_question = \"Give me the list of companies Paraveen worked for\"\n",
    "chain = (\n",
    "    {\"context\":retriever, \"question\":RunnablePassthrough()}\n",
    "    | prompt \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "response = chain.invoke(user_question)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 54.37it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 72.08it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 30.03it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 72.54it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 71.25it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 45.02it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 52.90it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 47.52it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 35.13it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 75.05it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 74.69it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:00<00:00, 76.06it/s]\n",
      "Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context, Praveen possesses the following technical skills:\n",
      "\n",
      "1. Programming languages:\n",
      "\t* Python\n",
      "2. Data science / AI libraries:\n",
      "\t* Pandas\n",
      "\t* Scikit-learn\n",
      "\t* Seaborn\n",
      "\t* Numpy\n",
      "\t* Spacy\n",
      "\t* Gensim\n",
      "\t* statsmodels\n",
      "\t* PyPDF\n",
      "\t* BeautifulSoup\n",
      "\t* LangChain\n",
      "3. Machine learning / AI models techniques:\n",
      "\t* Linear Regression\n",
      "\t* Logistic Regression\n",
      "\t* Decision Tree Models\n",
      "\t* Bagging & Boosting Ensemble models\n",
      "\t* Naïve Bayes\n",
      "\t* KNN\n",
      "\t* Neural Networks\n",
      "\t* SVM\n",
      "\t* K Means\n",
      "\t* Encoding\n",
      "\t* Data Cleaning\n",
      "\t* Feature Engineering\n",
      "\t* Regularization\n",
      "\t* Normalization\n",
      "4. Deep learning frameworks:\n",
      "\t* LLMs (Large Language Models)\n",
      "5. Cloud skills:\n",
      "\t* Python's scikit learn\n",
      "6. Big data technologies:\n",
      "\t* BigQuery SQL\n",
      "7. Database management systems:\n",
      "\t* Milvus\n",
      "8. Data visualization tools:\n",
      "\t* Superset\n",
      "9. Data engineering and pipeline development:\n",
      "\t* Docker\n"
     ]
    }
   ],
   "source": [
    "user_question = \"What technical skills does Praveen Possess ?\"\n",
    "chain = (\n",
    "    {\"context\":retriever, \"question\":RunnablePassthrough()}\n",
    "    | prompt \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "response = chain.invoke(user_question)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelexpenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
